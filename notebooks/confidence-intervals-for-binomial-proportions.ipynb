{
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[This work](http://notebooks.asorge.de) is licensed under a [Creative\n",
      "Commons Attribution 4.0 International\n",
      "License](http://creativecommons.org/licenses/by/4.0/).\n",
      "\n",
      "# Confidence Intervals for Binomial Proportions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats.distributions as dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider a discrete random variable $X$ which indicates either \"success\"\n",
      "($X=1$) or \"failure\" ($X=0$) as the outcome of a random experiment.\n",
      "Such an experiment is called a *Bernoulli trial*.\n",
      "The probability of success is $p=P\\{X=1\\}$, and the probability of failure is\n",
      "$P\\{X=0\\}=1-p$.\n",
      "Repeating a Bernoulli trial $n$ times means drawing a sample of $n$ independent\n",
      "and identically distributed random variables $X_i$.\n",
      "The probability mass function of observing $k$ success is the binomial\n",
      "distribution\n",
      "\n",
      "$$\n",
      "\\binom{n}{k} p^k (1-p)^{n-k}.\n",
      "$$\n",
      "\n",
      "The expected number of successes is $np$ with variance $np(1-p)$.\n",
      "Hence, the success probability $p$ is the expected *proportion* of successes\n",
      "$\\frac{k}{n}$, with variance $p(1-p)/n$.\n",
      "\n",
      "Let $\\hat{p}:=\\frac{k}{n}$ denote the sample proportion which is the unbiased\n",
      "(and maximum likelihood) estimator for the success probability $p$, and let\n",
      "$\\hat{\\sigma} := \\hat{p}(1-\\hat{p})/n$ denote the sample variance.\n",
      "Then the normal $1-\\alpha$ confidence interval for the binomial proportion\n",
      "$\\hat{p}$ is\n",
      "\n",
      "$$\n",
      "\\hat{p} \\pm z_{\\alpha/2} \\hat{\\sigma},\n",
      "$$\n",
      "\n",
      "where $z_{\\alpha/2}$ is the $1 - \\frac{\\alpha}{2}$ quantile of the standard\n",
      "normal distribution.\n",
      "This normal confidence interval is also called the *Wald confidence interval*.\n",
      "\n",
      "As Cameron <cite data-cite=\"Cameron2011Estimation\">([Cameron, 2011])</cite>\n",
      "puts it, this normal approximation \"suffers a *systematic* decline in\n",
      "performance both for small $n$ and towards extreme values of $p$ near $0$ and\n",
      "$1$, generating binomial [confidence intervals] with effective coverage far\n",
      "below the desired level.\" (see also <cite\n",
      "data-cite=\"Agresti1998Approximate\">([Agresti & Coull, 1998])</cite> and \n",
      "<cite data-cite=\"DasGupta2001Interval\">([DasGupta et al., 2001])</cite>)\n",
      "\n",
      "[DasGupta et al., 2001]: http://dx.doi.org/10.1214/ss/1009213286\n",
      "\n",
      "[Agresti & Coull, 1998]: http://dx.doi.org/10.2307/2685469\n",
      "\n",
      "A different approach to quantifying uncertainty is Bayesian inference.\n",
      "The normal (frequentist) $1 - \\alpha$ confidence interval derives from a\n",
      "procedure that produces $1 - \\alpha$ confidence intervals that contain the true\n",
      "parameter value $100(1-\\alpha)\\%$ of the times.\n",
      "The $1-\\alpha$ credible interval of Bayesian inference is the interval in which\n",
      "the parameter lies with probability $1-\\alpha$. \n",
      "<cite data-cite=\"Wasserman2004All\">([Wasserman, 2004])</cite>\n",
      "\n",
      "Specifically, Bayesian inference employes Bayes' theorem\n",
      "$$\n",
      "P(A|B) = \\frac{P(B|A) P(A)}{P(B)}.\n",
      "$$\n",
      "Associate $A$ with the parameter and $B$ with the outcome from an experiment\n",
      "(the data).\n",
      "Then $P(A)$ is the *prior* probability of the parameter event $A$, with the\n",
      "*likelihood* $P(B|A)$ of the outcome event $B$ given the parameter event $A$.\n",
      "The *posterior* $P(A|B)$ is the probability of the parameter event $A$ given\n",
      "the outcome event $B$.\n",
      "\n",
      "For probability density functions, this reads\n",
      "$$\n",
      "f(\\theta|x) = \\frac{f(x|\\theta) f(\\theta)}{\\int d\\theta f(\\theta|x)f(\\theta)}\n",
      "$$\n",
      "with parameter $\\theta$ and data $x$.\n",
      "A Bayesian interval estimate is the $1 - \\alpha$ *posterior interval* or\n",
      "*credible interval* $(l,u)$ with $\\int_{-\\infty}^l d\\theta f(\\theta|x) =\n",
      "\\int_{u}^{+\\infty} d\\theta f(\\theta | x) = \\alpha/2$ such that $P(\\theta \\in\n",
      "(l,u)|x) = 1 - \\alpha$.\n",
      "\n",
      "For $n$ independent Bernoulli trials with common success probability $p$, the\n",
      "*likelihood* to have $k$ successes given $p$ is the binomial distribution\n",
      "$$\n",
      "P(k|p) = \\binom{n}{k} p^k (1-p)^{n-k} \\equiv B(a,b),\n",
      "$$\n",
      "where $B(a,b)$ is the *Beta distribution* with parameters $a = k+1$ and $b = n\n",
      "- k + 1$.\n",
      "Assuming a uniform prior $P(p) = 1$, the *posterior* is <cite\n",
      "data-cite=\"Wasserman2004All\">([Wasserman, 2004])</cite>\n",
      "$$\n",
      "P(p|k) = P(k|p)=B(a,b).\n",
      "$$\n",
      "A point estimate is the posterior mean\n",
      "$$\n",
      "\\bar{p} = \\frac{k+1}{n+2}\n",
      "$$\n",
      "with $1 - \\alpha$ credible interval $(p_l, p_u)$ given by\n",
      "$$\n",
      "\\int_0^{p_l} dp B(a,b) = \\int_{p_u}^1 dp B(a,b) = \\frac{\\alpha}{2}.\n",
      "$$\n",
      "\n",
      "[Wasserman, 2004]: http://dx.doi.org/10.1007/978-0-387-21736-9\n",
      "\n",
      "[Cameron, 2011]: http://dx.doi.org/10.1071/as10046\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}