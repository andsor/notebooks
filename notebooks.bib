@article{Singer2009NelderMead,
    abstract = {The {Nelder-Mead} algorithm or simplex search algorithm, originally published in 1965 (Nelder and Mead, 1965), is one of the best known algorithms for multidimensional unconstrained optimization without derivatives. This method should not be confused with Dantzig's simplex method for linear programming, which is completely different, as it solves a linearly constrained linear problem.

The basic algorithm is quite simple to understand and very easy to use. For these reasons, it is very popular in many fields of science and technology, especially in chemistry and medicine.

The method does not require any derivative information, which makes it suitable for problems with non-smooth functions. It is widely used to solve parameter estimation and similar statistical problems, where the function values are uncertain or subject to noise. It can also be used for problems with discontinuous functions, which occur frequently in statistics and experimental mathematics.},
    author = {Singer, Sa\v{s}a and Nelder, John},
    citeulike-article-id = {13343996},
    citeulike-linkout-0 = {http://dx.doi.org/10.4249/scholarpedia.2928},
    doi = {10.4249/scholarpedia.2928},
    journal = {Scholarpedia},
    keywords = {optimization},
    number = {7},
    pages = {2928+},
    posted-at = {2014-09-03 09:22:14},
    priority = {0},
    title = {{Nelder-Mead} algorithm},
    url = {http://dx.doi.org/10.4249/scholarpedia.2928},
    volume = {4},
    year = {2009}
}

@article{Nelder1965Simplex,
    abstract = {A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems.},
    author = {Nelder, J. A. and Mead, R.},
    citeulike-article-id = {3009487},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/7.4.308},
    citeulike-linkout-1 = {http://comjnl.oxfordjournals.org/content/7/4/308.abstract},
    citeulike-linkout-2 = {http://comjnl.oxfordjournals.org/content/7/4/308.full.pdf},
    citeulike-linkout-3 = {http://comjnl.oxfordjournals.org/cgi/content/abstract/7/4/308},
    doi = {10.1093/comjnl/7.4.308},
    journal = {The Computer Journal},
    keywords = {optimization},
    number = {4},
    pages = {308--313},
    posted-at = {2014-09-03 09:22:02},
    priority = {0},
    publisher = {Oxford University Press},
    title = {A Simplex Method for Function Minimization},
    url = {http://dx.doi.org/10.1093/comjnl/7.4.308},
    volume = {7},
    year = {1965}
}

@misc{Jones2001SciPy,
    author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu},
    citeulike-article-id = {13344001},
    citeulike-linkout-0 = {http://www.scipy.org},
    keywords = {scientific\_computing},
    note = {http://www.scipy.org/},
    posted-at = {2014-09-03 09:21:51},
    priority = {0},
    title = {{SciPy}: Open source scientific tools for {Python}},
    url = {http://www.scipy.org},
    year = {2001--}
}

@article{Oliphant2007Python,
    abstract = {By itself, Python is an excellent "steering" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.},
    author = {Oliphant, Travis E.},
    citeulike-article-id = {5662279},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2007.58},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/mcse.2007.58},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4160250},
    doi = {10.1109/mcse.2007.58},
    journal = {Computing in Science \& Engineering},
    keywords = {scientific\_computing},
    number = {3},
    pages = {10--20},
    posted-at = {2014-09-03 09:21:40},
    priority = {2},
    title = {Python for Scientific Computing},
    url = {http://dx.doi.org/10.1109/mcse.2007.58},
    volume = {9},
    year = {2007}
}

@article{Price2002Convergent,
    abstract = {The {Nelder–Mead} algorithm (1965) for unconstrained optimization has been used extensively to solve parameter estimation and other problems. Despite its age, it is still the method of choice for many practitioners in the fields of statistics, engineering, and the physical and medical sciences because it is easy to code and very easy to use. It belongs to a class of methods which do not require derivatives and which are often claimed to be robust for problems with discontinuities or where the function values are noisy. Recently (1998), it has been shown that the method can fail to converge or converge to nonsolutions on certain classes of problems. Only very limited convergence results exist for a restricted class of problems in one or two dimensions. In this paper, a provably convergent variant of the {Nelder–Mead} simplex method is presented and analyzed. Numerical results are included to show that the modified algorithm is effective in practice.},
    author = {Price, C. J. and Coope, I. D. and Byatt, D.},
    booktitle = {Journal of Optimization Theory and Applications},
    citeulike-article-id = {13344003},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a\%253a1014849028575},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1023/A\%3A1014849028575},
    doi = {10.1023/a\%253a1014849028575},
    keywords = {optimization},
    number = {1},
    pages = {5--19},
    posted-at = {2014-09-03 09:21:28},
    priority = {0},
    title = {A Convergent Variant of the {Nelder–Mead} Algorithm},
    url = {http://dx.doi.org/10.1023/a\%253a1014849028575},
    volume = {113},
    year = {2002}
}

@article{Singer2004Efficient,
    abstract = {The {Nelder–Mead} or simplex search algorithm is one of the best known algorithms for unconstrained optimization of non–smooth functions. Even though the basic algorithm is quite simple, it is implemented in many different ways. Apart from some minor computational details, the main difference between various implementations lies in the selection of convergence (or termination) tests, which are used to break the iteration process. A fairly simple efficiency analysis of each iteration step reveals a potential computational bottleneck in the domain convergence test. To be efficient, such a test has to be sublinear in the number of vertices of the working simplex. We have tested some of the most common implementations of the {Nelder–Mead} algorithm, and none of them is efficient in this sense.

Therefore, we propose a simple and efficient domain convergence test and discuss some of its properties. This test is based on tracking the volume of the working simplex throughout the iterations. Similar termination tests can also be applied in some other simplex–based direct search methods.},
    author = {Singer, Sa\v{s}a and Singer, Sanja},
    citeulike-article-id = {13344005},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/anac.200410015},
    doi = {10.1002/anac.200410015},
    journal = {Applied Numerical Analysis \& Computational Mathematics},
    keywords = {optimization},
    number = {2},
    pages = {524--534},
    posted-at = {2014-09-03 09:21:14},
    priority = {0},
    title = {Efficient Implementation of the {Nelder-Mead} Search Algorithm},
    url = {http://dx.doi.org/10.1002/anac.200410015},
    volume = {1},
    year = {2004}
}

@article{Spendley1962Sequential,
    abstract = {A technique for empirical optimisation is presented in which a sequence of experimental designs each in the form of a regular or irregular simplex is used, each simplex having all vertices but one in common with the preceding simplex, and being completed by one new point. Reasons for the choice of design are outlined, and a formal procedure given. The performance of the technique in the presence and absence of error is studied and it is shown (a) that in the presence of error the rate of advance is inversely proportional to the error standard deviation, so that replication of observations is not beneficial, and (b) that the ?efficiency? of the technique appears to increase in direct proportion to the number of factors investigated. It is also noted that, since the direction of movement from each simplex is dependent solely on the ranking of the observations, the technique may be used even in circumstances when a response cannot be quantitatively assessed. Attention is drawn to the ease with which second-order designs having the minimum number of experimental points may be derived from a regular simplex, and a fitting procedure which avoids a direct matrix inversion is suggested. In a brief appendix one or two new rotatable designs derivable from a simplex are noted.},
    author = {Spendley, W. and Hext, G. R. and Himsworth, F. R.},
    citeulike-article-id = {13344006},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00401706.1962.10490033},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1962.10490033},
    doi = {10.1080/00401706.1962.10490033},
    journal = {Technometrics},
    keywords = {optimization},
    number = {4},
    pages = {441--461},
    posted-at = {2014-09-03 09:21:05},
    priority = {0},
    title = {Sequential Application of Simplex Designs in Optimisation and Evolutionary Operation},
    url = {http://dx.doi.org/10.1080/00401706.1962.10490033},
    volume = {4},
    year = {1962}
}

@article{Lagarias1998Convergence,
    abstract = {The {Nelder--Mead} simplex algorithm, first published in 1965, is an enormously popular direct search method for multidimensional unconstrained minimization. Despite its widespread use, essentially no theoretical results have been proved explicitly for the {Nelder--Mead} algorithm. This paper presents convergence properties of the {Nelder--Mead} algorithm applied to strictly convex functions in dimensions 1 and 2. We prove convergence to a minimizer for dimension 1, and various limited convergence results for dimension 2. A counterexample of {McKinnon} gives a family of strictly convex functions in two dimensions and a set of initial conditions for which the {Nelder--Mead} algorithm converges to a nonminimizer. It is not yet known whether the {Nelder--Mead} method can be proved to converge to a minimizer for a more specialized class of convex functions in two dimensions.},
    author = {Lagarias, Jeffrey C. and Reeds, James A. and Wright, Margaret H. and Wright, Paul E.},
    citeulike-article-id = {3130144},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=588893.589108},
    citeulike-linkout-1 = {http://dx.doi.org/10.1137/s1052623496303470},
    doi = {10.1137/s1052623496303470},
    journal = {SIAM Journal on Optimization},
    keywords = {optimization},
    number = {1},
    pages = {112--147},
    posted-at = {2014-09-03 09:20:53},
    priority = {0},
    title = {Convergence Properties of the {Nelder--Mead} Simplex Method in Low Dimensions},
    url = {http://dx.doi.org/10.1137/s1052623496303470},
    volume = {9},
    year = {1998}
}

@article{Kolda2003Optimization,
    abstract = {Direct search methods are best known as unconstrained optimization techniques that do not explicitly use derivatives. Direct search methods were formally proposed and widely applied in the 1960s but fell out of favor with the mathematical optimization community by the early 1970s because they lacked coherent mathematical analysis. Nonetheless, users remained loyal to these methods, most of which were easy to program, some of which were reliable. In the past fifteen years, these methods have seen a revival due, in part, to the appearance of mathematical analysis, as well as to interest in parallel and distributed computing.

This review begins by briefly summarizing the history of direct search methods and considering the special properties of problems for which they are well suited. Our focus then turns to a broad class of methods for which we provide a unifying framework that lends itself to a variety of convergence results. The underlying principles allow generalization to handle bound constraints and linear constraints. We also discuss extensions to problems with nonlinear constraints.},
    author = {Kolda, Tamara G. and Lewis, Robert M. and Torczon, Virginia},
    citeulike-article-id = {9942868},
    citeulike-linkout-0 = {http://dx.doi.org/10.1137/s003614450242889},
    doi = {10.1137/s003614450242889},
    journal = {SIAM Review},
    keywords = {optimization},
    number = {3},
    pages = {385--482},
    posted-at = {2014-09-03 09:20:41},
    priority = {0},
    title = {Optimization by Direct Search: New Perspectives on Some Classical and Modern Methods},
    url = {http://dx.doi.org/10.1137/s003614450242889},
    volume = {45},
    year = {2003}
}

@article{Wenzel2008Percolation,
    abstract = {The compact Abelian Higgs model is simulated on a cubic lattice where it possesses vortex lines and pointlike magnetic monopoles as topological defects. The focus of this high-precision Monte Carlo study is on the vortex network, which is investigated by means of percolation observables. In the region of the phase diagram where the Higgs and confinement phases are separated by a first-order transition, it is shown that the vortices percolate right at the phase boundary, and that the first-order nature of the transition is reflected by the network. In the crossover region, where the phase boundary ceases to be first order, the vortices are shown to still percolate. In contrast to other observables, the percolation observables show finite-size scaling. The exponents characterizing the critical behavior of the vortices in this region are shown to fall in the random percolation universality class.},
    author = {Wenzel, Sandro and Bittner, Elmar and Janke, Wolfhard and Schakel, Adriaan M. J.},
    citeulike-article-id = {13343945},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.nuclphysb.2007.10.024},
    doi = {10.1016/j.nuclphysb.2007.10.024},
    journal = {Nuclear Physics B},
    keywords = {data\_analysis, percolation, phase\_transition},
    pages = {344--361},
    posted-at = {2014-09-02 06:53:32},
    priority = {0},
    title = {Percolation of vortices in the {3D} Abelian lattice Higgs model},
    url = {http://dx.doi.org/10.1016/j.nuclphysb.2007.10.024},
    volume = {793},
    year = {2008}
}

@article{Bhattacharjee2001Measure,
    abstract = {Data collapse is a way of establishing scaling and extracting associated exponents in problems showing self-similar or self-affine characteristics as, for example, in equilibrium or non-equilibrium phase transitions, in critical phases, in dynamics of complex systems and many others.  We propose a measure to quantify the nature of data collapse. Via a minimization of this measure, the exponents and their error-bars can be obtained.  The procedure is illustrated by considering finite-size-scaling near phase transitions and quite strikingly recovering the exact exponents.},
    author = {Bhattacharjee, Somendra M. and Seno, Flavio},
    citeulike-article-id = {4139720},
    citeulike-linkout-0 = {http://dx.doi.org/10.1088/0305-4470/34/33/302},
    citeulike-linkout-1 = {http://iopscience.iop.org/0305-4470/34/33/302},
    doi = {10.1088/0305-4470/34/33/302},
    journal = {Journal of Physics A: Mathematical and General},
    keywords = {data\_analysis, phase\_transition},
    month = aug,
    number = {33},
    pages = {6375--6380},
    posted-at = {2014-09-02 06:46:29},
    priority = {0},
    title = {A measure of data collapse for scaling},
    url = {http://dx.doi.org/10.1088/0305-4470/34/33/302},
    volume = {34},
    year = {2001}
}

@book{Bevington2003Data,
    address = {Boston},
    author = {Bevington, Philip R. and Robinson, D. Keith},
    citeulike-article-id = {13342054},
    edition = {Third},
    keywords = {data\_analysis, textbook},
    posted-at = {2014-08-31 13:59:38},
    priority = {0},
    publisher = {McGraw-Hill},
    title = {Data Reduction and Error Analysis for the Physical Sciences},
    year = {2003}
}

@book{Newman1999Monte,
    abstract = {{This book provides an introduction to Monte Carlo simulations in classical statistical physics and is aimed both at students beginning work in the field and at more experienced researchers who wish to learn more about Monte Carlo methods. The material covered includes methods for both equilibrium and out of equilibrium systems, and common algorithms like the Metropolis and heat-bath algorithms are discussed in detail, as well as more sophisticated ones such as continuous time Monte Carlo, cluster algorithms, multigrid methods, entropic sampling and simulated tempering. Data analysis techniques are also explained starting with straightforward measurement and error-estimation techniques and progressing to topics such as the single and multiple histogram methods and finite size scaling. The last few chapters of the book are devoted to implementation issues, including discussions of such topics as lattice representations, efficient implementation of data structures, multispin coding, parallelization of Monte Carlo algorithms, and random number generation. At the end of the book the authors give a number of example programs demonstrating the applications of these techniques to a variety of well-known models.}},
    author = {Newman, M. E. J. and Barkema, G. T.},
    citeulike-article-id = {1221914},
    citeulike-linkout-0 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&\#38;path=ASIN/0198517971},
    citeulike-linkout-1 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0198517971},
    citeulike-linkout-10 = {http://www.librarything.com/isbn/0198517971},
    citeulike-linkout-11 = {http://www.worldcat.org/oclc/40927360},
    citeulike-linkout-2 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0198517971},
    citeulike-linkout-3 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0198517971},
    citeulike-linkout-4 = {http://www.amazon.jp/exec/obidos/ASIN/0198517971},
    citeulike-linkout-5 = {http://www.amazon.co.uk/exec/obidos/ASIN/0198517971/citeulike00-21},
    citeulike-linkout-6 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0198517971},
    citeulike-linkout-7 = {http://www.worldcat.org/isbn/0198517971},
    citeulike-linkout-8 = {http://books.google.com/books?vid=ISBN0198517971},
    citeulike-linkout-9 = {http://www.amazon.com/gp/search?keywords=0198517971\&index=books\&linkCode=qs},
    isbn = {9780198517979},
    keywords = {monte\_carlo, statistical\_physics, textbook},
    posted-at = {2014-08-31 13:55:22},
    priority = {0},
    publisher = {Oxford University Press},
    title = {Monte Carlo Methods in Statistical Physics},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0198517971},
    year = {1999}
}

@book{Binder2010Monte,
    address = {Berlin, Heidelberg},
    author = {Binder, Kurt and Heermann, Dieter W.},
    citeulike-article-id = {13318034},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-03163-2},
    doi = {10.1007/978-3-642-03163-2},
    isbn = {978-3-642-03162-5},
    keywords = {monte\_carlo, phase\_transition, simulation, statistical\_physics, textbook},
    posted-at = {2014-08-31 13:39:02},
    priority = {0},
    publisher = {Springer},
    title = {Monte Carlo Simulation in Statistical Physics},
    url = {http://dx.doi.org/10.1007/978-3-642-03163-2},
    year = {2010}
}

@book{Strutz2011Data,
    address = {Wiesbaden},
    author = {Strutz, Tilo},
    citeulike-article-id = {13341905},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9783834810229},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9783834810229},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9783834810229\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9783834810229},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/794709654},
    isbn = {9783834810229},
    keywords = {data\_analysis, statistics, textbook},
    posted-at = {2014-08-31 09:20:23},
    priority = {0},
    publisher = {Vieweg + Teubner},
    title = {Data fitting and uncertainty : a practical introduction to weighted least squares and beyond},
    url = {http://www.worldcat.org/isbn/9783834810229},
    year = {2011}
}

@unpublished{Melchert2009AutoScalepy,
    abstract = {{autoScale}.py is a program that performs an automatic finite-size scaling
analysis for given sets of simulated data. It implements a quite general
scaling assumption and optimizes an initial set of scaling parameters that
enforce a data collapse of the different data sets. The presented guide
describes how the program works, it presents a detailed example and finally
gives some hints on how to improve the results of a scaling analysis.},
    archivePrefix = {arXiv},
    author = {Melchert, O.},
    citeulike-article-id = {6994170},
    citeulike-linkout-0 = {http://arxiv.org/abs/0910.5403},
    citeulike-linkout-1 = {http://arxiv.org/pdf/0910.5403},
    eprint = {0910.5403},
    keywords = {computational\_physics, data\_analysis, phase\_transition},
    month = oct,
    posted-at = {2014-08-31 09:17:29},
    priority = {0},
    title = {{autoScale}.py - A program for automatic finite-size scaling analyses: A user's guide},
    url = {http://arxiv.org/abs/0910.5403},
    year = {2009}
}

@article{Houdayer2004Lowtemperature,
    abstract = {We perform Monte Carlo simulations of large two-dimensional Gaussian Ising spin glasses down to very low temperatures {β=1∕T}=50. Equilibration is ensured by using a cluster algorithm including Monte Carlo moves consisting of flipping fundamental excitations. We study the thermodynamic behavior using the Binder cumulant, the spin-glass susceptibility, the distribution of overlaps, the overlap with the ground state, and the specific heat. We confirm that Tc=0. All results are compatible with an algebraic divergence of the correlation length with an exponent ν. We find −1∕ν=−0.295(40), which is compatible with the value for the domain-wall and droplet exponent θ≈−0.29 found previously in ground-state studies. Hence the thermodynamic behavior of this model seems to be governed by one single exponent.},
    author = {Houdayer, J\'{e}r\^{o}me and Hartmann, Alexander},
    citeulike-article-id = {13341409},
    citeulike-linkout-0 = {http://dx.doi.org/10.1103/physrevb.70.014418},
    doi = {10.1103/physrevb.70.014418},
    journal = {Physical Review B},
    keywords = {phase\_transition},
    number = {1},
    pages = {014418+},
    posted-at = {2014-08-31 08:07:33},
    priority = {0},
    title = {Low-temperature behavior of two-dimensional Gaussian Ising spin glasses},
    url = {http://dx.doi.org/10.1103/physrevb.70.014418},
    volume = {70},
    year = {2004}
}

@article{Kawashima1993Critical,
    abstract = {The three-dimensional ± J Ising spin glass model is investigated by means of Monte Carlo simulation. In uniform fields of various strength, the {Edwards-Anderson} susceptibility χ {EA} Q is calculated at T =0.9 J which is lower than the transition temperature in the zero-field case. It is found that χ {EA} decreases monotonically when the field strength is increased and that the data do not suggest a phase transition in a finite field. The best parameters for the scaling function of the form {χEA}({H)≃lψχ\~{}EA}(({H−Hc})l−ϕ) are estimated to be H c =0.00(10) J , ψ=2.16(22) and φ=-1.13(6). These results support the hypothesis that the phase transition does not exist in a finite magnetic field. \sloppy},
    author = {Kawashima, Naoki and Ito, Nobuyasu},
    citeulike-article-id = {13341412},
    citeulike-linkout-0 = {http://dx.doi.org/10.1143/jpsj.62.435},
    doi = {10.1143/jpsj.62.435},
    journal = {Journal of the Physical Society of Japan},
    keywords = {phase\_transition},
    number = {2},
    pages = {435--438},
    posted-at = {2014-08-31 08:07:15},
    priority = {0},
    title = {Critical Behavior of the {Three-Dimensional} ±J Model in a Magnetic Field},
    url = {http://dx.doi.org/10.1143/jpsj.62.435},
    volume = {62},
    year = {1993}
}

@book{Wasserman2004All,
    author = {Wasserman, Larry},
    citeulike-article-id = {13336822},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-21736-9},
    doi = {10.1007/978-0-387-21736-9},
    isbn = {978-1-4419-2322-6},
    keywords = {statistics, textbook},
    posted-at = {2014-08-25 08:41:45},
    priority = {2},
    publisher = {Springer New York},
    title = {All of Statistics},
    url = {http://dx.doi.org/10.1007/978-0-387-21736-9},
    year = {2004}
}

@article{DasGupta2001Interval,
    abstract = {We revisit the problem of interval estimation of a binomial proportion. The erratic behavior of the coverage probability of the standard Wald confidence interval has previously been remarked on in the literature (Blyth and Still, Agresti and Coull, Santner and others). We begin by showing that the chaotic coverage properties of the Wald interval are far more persistent than is appreciated. Furthermore, common textbook prescriptions regarding its safety are misleading and defective in several respects and cannot be trusted.

This leads us to consideration of alternative intervals. A number of natural alternatives are presented, each with its motivation and context. Each interval is examined for its coverage probability and its length. Based on this analysis, we recommend the Wilson interval or the equal-tailed Jeffreys prior interval for small n and the interval suggested in Agresti and Coull for larger n. We also provide an additional frequentist justification for use of the Jeffreys interval.},
    author = {DasGupta, Anirban and Cai, Tony T. and Brown, Lawrence D.},
    citeulike-article-id = {7557924},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/ss/1009213286},
    doi = {10.1214/ss/1009213286},
    journal = {Statistical Science},
    keywords = {statistics},
    number = {2},
    pages = {101--133},
    posted-at = {2014-08-25 07:51:04},
    priority = {0},
    title = {Interval Estimation for a Binomial Proportion},
    url = {http://dx.doi.org/10.1214/ss/1009213286},
    volume = {16},
    year = {2001}
}

@article{Agresti1998Approximate,
    abstract = {For interval estimation of a proportion, coverage probabilities tend to be too large for "exact" confidence intervals based on inverting the binomial test and too small for the interval based on inverting the Wald large-sample normal test (i.e., sample proportion ± z-score × estimated standard error). Wilson's suggestion of inverting the related score test with null rather than estimated standard error yields coverage probabilities close to nominal confidence levels, even for very small sample sizes. The 95\% score interval has similar behavior as the adjusted Wald interval obtained after adding two "successes" and two "failures" to the sample. In elementary courses, with the score and adjusted Wald methods it is unnecessary to provide students with awkward sample size guidelines.},
    author = {Agresti, Alan and Coull, Brent A.},
    citeulike-article-id = {1060968},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2685469},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2685469},
    doi = {10.2307/2685469},
    journal = {The American Statistician},
    keywords = {statistics},
    number = {2},
    pages = {119--126},
    posted-at = {2014-08-25 07:48:42},
    priority = {0},
    publisher = {American Statistical Association},
    title = {Approximate Is Better than "Exact" for Interval Estimation of Binomial Proportions},
    url = {http://dx.doi.org/10.2307/2685469},
    volume = {52},
    year = {1998}
}

@article{Cameron2011Estimation,
    abstract = {I present a critical review of techniques for estimating confidence intervals on binomial population proportions inferred from success counts in small to intermediate samples. Population proportions arise frequently as quantities of interest in astronomical research; for instance, in studies aiming to constrain the bar fraction, active galactic nucleus fraction, supermassive black hole fraction, merger fraction, or red sequence fraction from counts of galaxies exhibiting distinct morphological features or stellar populations. However, two of the most widely-used techniques for estimating binomial confidence intervals — the 'normal approximation' and the Clopper \& Pearson approach — are liable to misrepresent the degree of statistical uncertainty present under sampling conditions routinely encountered in astronomical surveys, leading to an ineffective use of the experimental data (and, worse, an inefficient use of the resources expended in obtaining that data). Hence, I provide here an overview of the fundamentals of binomial statistics with two principal aims: (I) to reveal the ease with which (Bayesian) binomial confidence intervals with more satisfactory behaviour may be estimated from the quantiles of the beta distribution using modern mathematical software packages (e.g. r, matlab, mathematica, idl, python); and (ii) to demonstrate convincingly the major flaws of both the 'normal approximation' and the Clopper \& Pearson approach for error estimation.},
    author = {Cameron, Ewan},
    citeulike-article-id = {13336801},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8794731},
    citeulike-linkout-1 = {http://dx.doi.org/10.1071/as10046},
    doi = {10.1071/as10046},
    journal = {Publications of the Astronomical Society of Australia},
    keywords = {statistics},
    pages = {128--139},
    posted-at = {2014-08-25 07:44:56},
    priority = {0},
    title = {On the Estimation of Confidence Intervals for Binomial Population Proportions in Astronomy: The Simplicity and Superiority of the Bayesian Approach},
    url = {http://dx.doi.org/10.1071/as10046},
    volume = {28},
    year = {2011}
}

@book{Asmussen2007Stochastic,
    author = {Asmussen, S{\o}ren and Glynn, Peter W.},
    citeulike-article-id = {13331529},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-69033-9},
    doi = {10.1007/978-0-387-69033-9},
    isbn = {978-0-387-30679-7},
    keywords = {stochastic\_methods, textbook},
    posted-at = {2014-08-21 06:59:39},
    priority = {0},
    publisher = {Springer New York},
    series = {Stochastic Modelling and Applied Probability},
    title = {Stochastic Simulation: Algorithms and Analysis},
    url = {http://dx.doi.org/10.1007/978-0-387-69033-9},
    volume = {57},
    year = {2007}
}

